{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MAI.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRVA8Szd8Eje"
      },
      "source": [
        "Notebook for model optimisation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoKhhUAvw7Fg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "117fe21b-559c-4307-8fdb-52aa9c42a87d"
      },
      "source": [
        "! pip install -q tensorflow-model-optimization"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |██                              | 10kB 28.2MB/s eta 0:00:01\r\u001b[K     |███▉                            | 20kB 35.1MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 30kB 24.0MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 40kB 18.1MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 51kB 15.0MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 61kB 14.0MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 71kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 81kB 14.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 92kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 102kB 15.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 112kB 15.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 122kB 15.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 133kB 15.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 143kB 15.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 153kB 15.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 163kB 15.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 174kB 15.2MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRFxaHU957xi"
      },
      "source": [
        "#set the channel number here\n",
        "channel = 36"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEx4VxbzFM5a"
      },
      "source": [
        "#allow file access\r\n",
        "from google.colab import files\r\n",
        "\r\n",
        "from tensorflow.keras.models import load_model\r\n",
        "\r\n",
        "import pickle\r\n",
        "\r\n",
        "#import shap  \r\n",
        "#import shap\r\n",
        "#shap.initjs()\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import tensorflow as tf\r\n",
        "#tf.compat.v1.disable_v2_behavior() #this was required for SHAP values\r\n",
        "#possibly worth using the below \r\n",
        "#tf.compat.v1.enable_eager_executionconfig=None, device_policy=None, execution_mode=None)\r\n",
        "from tensorflow import keras\r\n",
        "\r\n",
        "\r\n",
        "#borrowed form 5c16\r\n",
        "from keras import datasets\r\n",
        "from keras.layers import Dense, Flatten, Dropout, Activation\r\n",
        "from keras.regularizers import l2\r\n",
        "from keras.callbacks import ModelCheckpoint\r\n",
        "\r\n",
        "from keras.models import model_from_json\r\n",
        "\r\n",
        "\r\n",
        "from tensorflow.keras.callbacks import CSVLogger\r\n",
        "\r\n",
        "from IPython.display import clear_output\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline\r\n",
        "from matplotlib.ticker import MaxNLocator\r\n",
        "\r\n",
        "import pickle\r\n",
        "import sklearn as skl\r\n",
        "\r\n",
        "#r2 score\r\n",
        "#from keras import backend as K\r\n",
        "import tensorflow.keras.backend as K\r\n",
        "from sklearn.metrics import r2_score\r\n",
        "\r\n",
        "from sklearn import datasets, linear_model\r\n",
        "from sklearn.model_selection import cross_val_score\r\n",
        "\r\n",
        "#model optimisation api\r\n",
        "import tensorflow_model_optimization as tfmot\r\n",
        "\r\n",
        "import tempfile\r\n",
        "import os\r\n",
        "import zipfile\r\n",
        "\r\n",
        "%load_ext tensorboard\r\n",
        "\r\n",
        "from tabulate import tabulate"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUaWQfvzF40O"
      },
      "source": [
        "# Define some useful functions\r\n",
        "class PlotLossAccuracy(keras.callbacks.Callback):\r\n",
        "    def on_train_begin(self, logs={}):\r\n",
        "        self.i = 0\r\n",
        "        self.x = []\r\n",
        "        self.acc = []\r\n",
        "        self.losses = []\r\n",
        "        self.val_losses = []\r\n",
        "        self.val_acc = []\r\n",
        "        self.logs = []\r\n",
        "        self.metrics = []\r\n",
        "        self.val_metrics = []\r\n",
        "        \r\n",
        "\r\n",
        "    def on_epoch_end(self, epoch, logs={}):\r\n",
        "        \r\n",
        "        self.logs.append(logs)\r\n",
        "        self.x.append(int(self.i))\r\n",
        "        self.losses.append(logs.get('loss'))\r\n",
        "        self.val_losses.append(logs.get('val_loss'))\r\n",
        "        self.acc.append(logs.get('r_squared'))\r\n",
        "        self.val_acc.append(logs.get('val_r_squared'))\r\n",
        "        ###\r\n",
        "        self.metrics.append(logs.get('mean_absolute_percentage_error'))         #mean_squared_error\r\n",
        "        self.val_metrics.append(logs.get('val_mean_absolute_percentage_error')) #val_mean_squared_error\r\n",
        "        \r\n",
        "        \r\n",
        "        self.i += 1\r\n",
        "        \r\n",
        "        clear_output(wait=True)\r\n",
        "        plt.figure(figsize=(60, 20))\r\n",
        "        plt.plot([3, 1])\r\n",
        "\r\n",
        "        #plot 1 mean absolute percentage error\r\n",
        "        plt.subplot(131) \r\n",
        "        plt.plot(self.x, self.losses, label=\"train loss\")\r\n",
        "        plt.plot(self.x, self.val_losses, label=\"validation loss\")\r\n",
        "        plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\r\n",
        "        plt.ylabel('Mse')\r\n",
        "        plt.xlabel('epoch')\r\n",
        "        plt.title('MSE Value')\r\n",
        "        plt.legend()\r\n",
        "\r\n",
        "        #plot 2 r squared value\r\n",
        "        plt.subplot(133)         \r\n",
        "        plt.plot(self.x, self.acc, label=\"training r-squared\")\r\n",
        "        plt.plot(self.x, self.val_acc, label=\"validation r-squared\")\r\n",
        "        plt.legend()\r\n",
        "        plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\r\n",
        "        plt.ylabel('R-squared')\r\n",
        "        plt.xlabel('epoch')\r\n",
        "        plt.title('R-Squared Value')\r\n",
        "\r\n",
        "        #plot 3 mean squared error\r\n",
        "        plt.subplot(132)         \r\n",
        "        plt.plot(self.x, self.metrics, label=\"training mse\")\r\n",
        "        plt.plot(self.x, self.val_metrics, label=\"validation mse\")\r\n",
        "        plt.legend()\r\n",
        "        plt.ylabel('Mean absolute percentage Error')\r\n",
        "        plt.xlabel('epoch')\r\n",
        "        plt.title('Mean absolute percentage Error')\r\n",
        "        \r\n",
        "        plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\r\n",
        "        plt.show();\r\n",
        "        \r\n",
        "\r\n",
        "#creating a r^2 metric for the model evaluation\r\n",
        "def r_squared(y_true, y_pred):\r\n",
        "    SS_res =  K.sum(K.square( y_true-y_pred )) \r\n",
        "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) ) \r\n",
        "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\r\n",
        "\r\n",
        "    "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1n0YwZjAbhz"
      },
      "source": [
        "ch_names = np.arange(44).tolist()\n",
        "freqs = np.arange(191.6, 195.9, 0.1).tolist()\n",
        "for x in range(len(ch_names)):\n",
        "  ch_names[x] = \"Ch %.0f (%.1f)\" % (ch_names[x], freqs[x])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjvwilfOMYr0"
      },
      "source": [
        "#generate the train and validation datasets\r\n",
        "#retreiving both datasets from GitHub\r\n",
        "git_xval = 'https://raw.githubusercontent.com/p-owens/MAI/main/const_ch/new_model/x_val.csv'\r\n",
        "git_yval = 'https://raw.githubusercontent.com/p-owens/MAI/main/const_ch/new_model/y_val.csv'\r\n",
        "df_x = pd.read_csv(git_xval,\r\n",
        "                  index_col=False,\r\n",
        "                  header=None,\r\n",
        "                  names=ch_names)\r\n",
        "\r\n",
        "df_y = pd.read_csv(git_yval,\r\n",
        "                  index_col=False,\r\n",
        "                  header=None,\r\n",
        "                  names=ch_names)\r\n",
        "\r\n",
        "#dropping the frequences row for each training sample\r\n",
        "df_x = df_x.iloc[1::2]\r\n",
        "#print(df_x)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qafC3TXH3ZPW"
      },
      "source": [
        "#drop all rows where df_x has a value != 0\n",
        "df_chx = df_x[df_x[ch_names[channel]] !=0].iloc[500:,:]\n",
        "df_chy = df_y[df_y[ch_names[channel]] !=0].iloc[500:,:]\n",
        "df_chy = df_chy[ch_names[channel]]\n",
        "\n",
        "#convert to numpy arrays\n",
        "x_values = df_chx.to_numpy()\n",
        "y_values = df_chy.to_numpy()\n",
        "\n",
        "#adding some samples where the channel is 0\n",
        "#x values\n",
        "df_xzero = df_x.iloc[:500,:]\n",
        "x_values = np.concatenate((x_values, df_xzero.to_numpy()), axis=0)\n",
        "\n",
        "#y values\n",
        "df_yzero = df_y.iloc[:500,channel]\n",
        "y_values = np.concatenate((y_values, df_yzero.to_numpy()), axis=0)\n",
        "\n",
        "\n",
        "#generate the test/validation split\n",
        "val_split = .2\n",
        "x_train, x_val, y_train, y_val = skl.model_selection.train_test_split(x_values, y_values, test_size = val_split, random_state = 0)#renaimed x_rem and y_rem to x_values and y_values\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ncN0plVo40c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "061cbb5d-9a7c-439d-f591-3a90ecf48a4b"
      },
      "source": [
        "print(x_values.shape[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6712\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Fmp93Sl8xeo"
      },
      "source": [
        "#Using a dataset with 1 ch constantly on for the test set\n",
        "#retreiving both datasets from GitHub\n",
        "\n",
        "\n",
        "\n",
        "git_xval = ('https://raw.githubusercontent.com/p-owens/MAI/main/const_ch/new_model/test_set/ch{0}/x_val.csv'.format(channel))\n",
        "git_yval = ('https://raw.githubusercontent.com/p-owens/MAI/main/const_ch/new_model/test_set/ch{0}/y_val.csv'.format(channel))\n",
        "dfx = pd.read_csv(git_xval,\n",
        "                  index_col=False,\n",
        "                  header=None,\n",
        "                  names=ch_names                                   \n",
        "                 )\n",
        "dfy = pd.read_csv(git_yval,\n",
        "                  index_col=False,\n",
        "                  header=None,\n",
        "                  names=ch_names\n",
        "                 )\n",
        "\n",
        "#dropping the frequences row for each training sample\n",
        "dfx = dfx.iloc[1::2]\n",
        "\n",
        "#drop all rows where df_x has a value != 0\n",
        "dfx = dfx[dfx[ch_names[channel]] !=0]\n",
        "dfy = dfy[dfy[ch_names[channel]] !=0]\n",
        "dfy = dfy[ch_names[channel]]\n",
        "\n",
        "x_test = dfx.to_numpy()\n",
        "y_test = dfy.to_numpy()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DntGg6Abc1ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "154cfa47-e9ee-4e78-c673-cb540b4a2796"
      },
      "source": [
        "#loading a previously saved model\n",
        "\n",
        "model_dir = \"ch_36_ep_500_pct_err_5.3_mse_0.0_.h5\"\n",
        "\n",
        "l_rate = 1 * 1e-4\n",
        "opt = tf.keras.optimizers.Nadam(learning_rate=l_rate)\n",
        "\n",
        "model = tf.keras.models.load_model(model_dir, custom_objects={'r_squared': r_squared})\n",
        "model.compile(optimizer=opt,\n",
        "                       loss='mean_squared_error',\n",
        "                       metrics=[r_squared, tf.keras.metrics.MeanAbsolutePercentageError()])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 44)]              0         \n",
            "_________________________________________________________________\n",
            "1_dense (Dense)              (None, 360)               16200     \n",
            "_________________________________________________________________\n",
            "dropout_45 (Dropout)         (None, 360)               0         \n",
            "_________________________________________________________________\n",
            "2_dense (Dense)              (None, 180)               64980     \n",
            "_________________________________________________________________\n",
            "dropout_46 (Dropout)         (None, 180)               0         \n",
            "_________________________________________________________________\n",
            "3_dense (Dense)              (None, 180)               32580     \n",
            "_________________________________________________________________\n",
            "dropout_47 (Dropout)         (None, 180)               0         \n",
            "_________________________________________________________________\n",
            "4_dense (Dense)              (None, 90)                16290     \n",
            "_________________________________________________________________\n",
            "dropout_48 (Dropout)         (None, 90)                0         \n",
            "_________________________________________________________________\n",
            "5_dense (Dense)              (None, 45)                4095      \n",
            "_________________________________________________________________\n",
            "dropout_49 (Dropout)         (None, 45)                0         \n",
            "_________________________________________________________________\n",
            "6_dense (Dense)              (None, 1)                 46        \n",
            "=================================================================\n",
            "Total params: 134,191\n",
            "Trainable params: 134,191\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWRz-aY1iNps",
        "outputId": "9571ca41-3f88-4b6d-aab4-f34d89a7895c"
      },
      "source": [
        "#evaluating the loaded model\n",
        "\n",
        "\n",
        "results = model.evaluate(x_test,y_test)#, verbose=1)\n",
        "print(\"{name1}\\t\\t: {mse:<.4f}\\t(lower is better)\\n{name2}\\t: {percent_err:<.3%}\\t(lower is better)\".format(name1 = model.metrics_names[0],\n",
        "                                                                                                    name2 = model.metrics_names[2],\n",
        "                                                                                                    mse = results[0],\n",
        "                                                                                                    percent_err = results[2]/100))\n",
        "_, keras_file = tempfile.mkstemp('.h5')\n",
        "tf.keras.models.save_model(model, keras_file, include_optimizer=False)\n",
        "print('Saved baseline model to:', keras_file)\n",
        "\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0065 - r_squared: 0.4891 - mean_absolute_percentage_error: 5.4509\n",
            "loss\t\t: 0.0063\t(lower is better)\n",
            "mean_absolute_percentage_error\t: 5.320%\t(lower is better)\n",
            "Saved baseline model to: /tmp/tmpp4k5q8nc.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmW1H1AJIRDw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6068ff9b-2623-4f63-adf7-3ae7599329b5"
      },
      "source": [
        "\n",
        "layer_names = []\n",
        "\n",
        "for layer in model.layers:\n",
        "  if isinstance(layer, tf.keras.layers.Dense):\n",
        "    layer_names.append(layer.name)\n",
        "\n",
        "epochs_prune = 250\n",
        "batch_size = 400\n",
        "\n",
        "#validation_split = val_size # 10% of training set will be used for validation set. \n",
        "num_images = x_test.shape[0] * (1 - val_split)\n",
        "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs_prune            \n",
        "\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0,\n",
        "                                                               final_sparsity=0.975,\n",
        "                                                               begin_step=0,\n",
        "                                                               end_step=end_step)}  \n",
        "\n",
        "                                                                                                             \n",
        "\n",
        "\n",
        "def apply_pruning_to_dense(layer):\n",
        "  if isinstance(layer, tf.keras.layers.Dense):\n",
        "    if (layer.name in layer_names[1:-1]):\n",
        "      return tfmot.sparsity.keras.prune_low_magnitude(layer, **pruning_params)\n",
        "  return layer\n",
        "\n",
        "\n",
        "model_for_pruning = tf.keras.models.clone_model(\n",
        "    model,\n",
        "    clone_function=apply_pruning_to_dense)\n",
        "\n",
        "model_for_pruning.compile(optimizer = tf.keras.optimizers.Nadam(learning_rate=l_rate / 2),\n",
        "              loss='mean_squared_error',\n",
        "              metrics=[r_squared, tf.keras.metrics.MeanAbsolutePercentageError()])\n",
        "\n",
        "model_for_pruning.summary()\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:2281: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 44)]              0         \n",
            "_________________________________________________________________\n",
            "1_dense (Dense)              (None, 360)               16200     \n",
            "_________________________________________________________________\n",
            "dropout_45 (Dropout)         (None, 360)               0         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_2_dense  (None, 180)               129782    \n",
            "_________________________________________________________________\n",
            "dropout_46 (Dropout)         (None, 180)               0         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_3_dense  (None, 180)               64982     \n",
            "_________________________________________________________________\n",
            "dropout_47 (Dropout)         (None, 180)               0         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_4_dense  (None, 90)                32492     \n",
            "_________________________________________________________________\n",
            "dropout_48 (Dropout)         (None, 90)                0         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_5_dense  (None, 45)                8147      \n",
            "_________________________________________________________________\n",
            "dropout_49 (Dropout)         (None, 45)                0         \n",
            "_________________________________________________________________\n",
            "6_dense (Dense)              (None, 1)                 46        \n",
            "=================================================================\n",
            "Total params: 251,649\n",
            "Trainable params: 134,191\n",
            "Non-trainable params: 117,458\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "qLmMzFnFeDJ6",
        "outputId": "5c97a846-31d8-4bef-afb3-6f2fa114ddc3"
      },
      "source": [
        "\"\"\"\n",
        "#pruning the model\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "epochs_prune = 250\n",
        "batch_size = 400\n",
        "#validation_split = val_size # 10% of training set will be used for validation set. \n",
        "\n",
        "num_images = x_test.shape[0] * (1 - val_split)\n",
        "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs_prune\n",
        "\n",
        "\n",
        "\"\"\"          \n",
        "#pruning_params = {'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(target_sparsity=0.95,\n",
        "#                                                                            begin_step=0,\n",
        "#                                                                            end_step = end_step)}\n",
        "\"\"\"                                                                            \n",
        "\n",
        "# Define model for pruning - polynomial decay.\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0,\n",
        "                                                               final_sparsity=0.80,\n",
        "                                                               begin_step=0,\n",
        "                                                               end_step=end_step)}                                                            \n",
        "                                                     \n",
        "\n",
        "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "# `prune_low_magnitude` requires a recompile.\n",
        "model_for_pruning.compile(optimizer = tf.keras.optimizers.Nadam(learning_rate=l_rate / 2),\n",
        "              loss='mean_squared_error',\n",
        "              metrics=[r_squared, tf.keras.metrics.MeanAbsolutePercentageError()])\n",
        "\n",
        "model_for_pruning.summary()\n",
        "\"\"\""
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"                                                                            \\n\\n# Define model for pruning - polynomial decay.\\npruning_params = {\\n      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0,\\n                                                               final_sparsity=0.80,\\n                                                               begin_step=0,\\n                                                               end_step=end_step)}                                                            \\n                                                     \\n\\nmodel_for_pruning = prune_low_magnitude(model, **pruning_params)\\n\\n# `prune_low_magnitude` requires a recompile.\\nmodel_for_pruning.compile(optimizer = tf.keras.optimizers.Nadam(learning_rate=l_rate / 2),\\n              loss='mean_squared_error',\\n              metrics=[r_squared, tf.keras.metrics.MeanAbsolutePercentageError()])\\n\\nmodel_for_pruning.summary()\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "9T7o0qM4x1xu",
        "outputId": "dcc9893f-86a6-477f-d3bd-7bebe0226275"
      },
      "source": [
        "logdir = tempfile.mkdtemp()\n",
        "log_file = \"model_ch_{0}.csv\".format(channel)\n",
        "csv_log = CSVLogger(log_file)\n",
        "pltCallBack = PlotLossAccuracy()\n",
        "\n",
        "callbacks = [tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "             tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "             pltCallBack,\n",
        "             csv_log]\n",
        "  \n",
        "model_for_pruning.fit(x_train,\n",
        "                      y_train,\n",
        "                      batch_size=batch_size,\n",
        "                      verbose=1,\n",
        "                      epochs=epochs_prune, \n",
        "                      validation_data=(x_val, y_val), \n",
        "                      callbacks=callbacks)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-02bc26e4f9e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m                       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs_prune\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                       \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                       callbacks=callbacks)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1143\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m         \u001b[0mtraining_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m           \u001b[0mnumpy_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-addf44676cb6>\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_major_locator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxNLocator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minteger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \"\"\"\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     37\u001b[0m             display(\n\u001b[1;32m     38\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             )\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(*objs, **kwargs)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-2>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2124\u001b[0m                     \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2125\u001b[0m                     \u001b[0mbbox_inches_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2126\u001b[0;31m                     **kwargs)\n\u001b[0m\u001b[1;32m   2127\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2128\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    535\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_file_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m                 _png.write_png(renderer._renderer, fh, self.figure.dpi,\n\u001b[0;32m--> 537\u001b[0;31m                                metadata={**default_metadata, **metadata})\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprint_to_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95l-lJr3AvU1"
      },
      "source": [
        "#print the logfile of the model training data\n",
        "pd.read_csv(log_file, index_col='epoch')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrvgSM2Yx2gM"
      },
      "source": [
        "#Compare pruned model v unpruned model\n",
        "\n",
        "results_pruned = model_for_pruning.evaluate(x_test,y_test, verbose=1)\n",
        "print(\"Baseline Model:\\n{name1}\\t\\t: {mse:<.4f}\\t(lower is better)\\n{name2}\\t: {r2:<.2%}\\t(higher is better)\".format(name1 = model.metrics_names[0],\n",
        "                                                                                                    name2 = model.metrics_names[2],\n",
        "                                                                                                    mse = results[0],\n",
        "                                                                                                    r2 = results[2]/100))\n",
        "\n",
        "print(\"Pruned Model:\\n{namep1}\\t\\t: {pmse:<.4f}\\t(lower is better)\\n{namep2}\\t: {pr2:<.2%}\\t(higher is better)\".format(namep1 = model_for_pruning.metrics_names[0],\n",
        "                                                                                                    namep2 = model_for_pruning.metrics_names[2],\n",
        "                                                                                                    pmse = results_pruned[0],\n",
        "                                                                                                    pr2 = results_pruned[2]/100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdLm4hVYc1wx"
      },
      "source": [
        "#docs_infra: no_execute\n",
        "#%tensorboard --logdir={logdir}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mh9rqNbv6Sb1"
      },
      "source": [
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "\n",
        "_, pruned_keras_file = tempfile.mkstemp('.h5')\n",
        "tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
        "print('Saved pruned Keras model to:', pruned_keras_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHFhswJewVIv"
      },
      "source": [
        "headings = [\"Layer Name\", \"Total Parameters\", \"% Zero\"]\n",
        "format_row = \"{:<50}\" * (len(headings) + 1)\n",
        "\n",
        "values = []\n",
        "\n",
        "for i, w in enumerate(model_for_export.get_weights()):\n",
        "    if(w.size > 1 and (np.sum(w == 0) != 0)):\n",
        "      inner_list = []\n",
        "      inner_list.append(\"{}\".format({model_for_export.weights[i].name}))\n",
        "      inner_list.append(\"{}\".format(w.size))\n",
        "      inner_list.append(\"{:.2f}%\".format(np.sum(w == 0) / w.size * 100))\n",
        "      values.append(inner_list)\n",
        "\n",
        "print (tabulate(values, headings, numalign='left', tablefmt='rst'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbDeooECc3Gy"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
        "pruned_tflite_model = converter.convert()\n",
        "\n",
        "_, pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
        "\n",
        "with open(pruned_tflite_file, 'wb') as f:\n",
        "  f.write(pruned_tflite_model)\n",
        "\n",
        "print('Saved pruned TFLite model to:', pruned_tflite_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww8s8ynTc_7u"
      },
      "source": [
        "def get_gzipped_model_size(file):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sy6hQdtIdX7p"
      },
      "source": [
        "#creating a quantised tf lite model\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "quantized_and_pruned_tflite_model = converter.convert()\n",
        "\n",
        "_, quantized_and_pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
        "\n",
        "with open(quantized_and_pruned_tflite_file, 'wb') as f:\n",
        "  f.write(quantized_and_pruned_tflite_model)\n",
        "\n",
        "print('Saved quantized and pruned TFLite model to:', quantized_and_pruned_tflite_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rEgC11fjXgo"
      },
      "source": [
        "#function to evaluate the tflight model\n",
        "def eval_tf_lite(interpreter):\n",
        "\n",
        "  interpreter = tf.lite.Interpreter(model_content=quantized_and_pruned_tflite_model)\n",
        "  interpreter.allocate_tensors()\n",
        "\n",
        "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "  # Run predictions on ever y image in the \"test\" dataset.\n",
        "  y_pred = []\n",
        "  for test in (x_test):\n",
        "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "    # the model's input data format.\n",
        "    test = np.expand_dims(test, axis=0).astype(np.float32)\n",
        "    interpreter.set_tensor(input_index, test)\n",
        "\n",
        "    # Run inference.\n",
        "    interpreter.invoke()\n",
        "\n",
        "    prediction = interpreter.get_tensor(output_index)[0][0]\n",
        "    y_pred.append(prediction)\n",
        "\n",
        "  #return mean absolute percentage error\n",
        "  y_pred = np.array(y_pred)\n",
        "  mse = tf.keras.losses.MeanAbsolutePercentageError()                                 #tf.keras.losses.MeanSquaredError()\n",
        "  return mse(y_test, y_pred).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrdBUP_gM4dJ"
      },
      "source": [
        "tfl_acc = eval_tf_lite(quantized_and_pruned_tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzSXC_nxuqJX"
      },
      "source": [
        "orig = get_gzipped_model_size(keras_file)\n",
        "reduced = get_gzipped_model_size(pruned_keras_file)\n",
        "tf_lite = get_gzipped_model_size(pruned_tflite_file)\n",
        "tfl_quantized = get_gzipped_model_size(quantized_and_pruned_tflite_file)\n",
        "\n",
        "\n",
        "headings = [\"Model\", \"Size (bytes)\", \"Compression (%)\", \"Percent Error\"]\n",
        "values = []\n",
        "values.append([\"Keras - Baseline\", \"{:,d}\".format(orig), \"{:.1%}\".format(1 - orig/orig), \"{:.2%}\".format(results[2]/100)]) #origional = \n",
        "values.append([\"Keras - Pruned\", \"{:,d}\".format(reduced), \"{:.1%}\".format(1 - reduced/orig), \"{:.2%}\".format(results_pruned[2]/100)]) #pruned = \n",
        "values.append([\"TFlite - Pruned\", \"{:,d}\".format(tf_lite), \"{:.1%}\".format(1 - tf_lite/orig), \"{:.2%}\".format(results_pruned[2]/100)])    #tlf = \n",
        "values.append([\"TFlite - Pruned & Quantized\", \"{:,d}\".format(tfl_quantized), \"{:.1%}\".format(1 - tfl_quantized/orig), \"{:.2%}\".format(tfl_acc/100)])  #tfl_q = \n",
        "\n",
        "print (tabulate(values, headings, numalign='left', tablefmt='rst'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}