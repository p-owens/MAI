{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "new_model_base.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGsMjMl3rWJ1"
      },
      "source": [
        "#select a channel to operate on\n",
        "ch = 16"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AD_4d2MnvNR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1698acb-7500-4da7-a1f6-a7197a1c3eaa"
      },
      "source": [
        "#allow file access\n",
        "from google.colab import files\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "import pickle\n",
        "\n",
        "#import shap  \n",
        "#import shap\n",
        "#shap.initjs()\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "#tf.compat.v1.disable_v2_behavior() #this was required for SHAP values\n",
        "#possibly worth using the below \n",
        "#tf.compat.v1.enable_eager_executionconfig=None, device_policy=None, execution_mode=None)\n",
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "#borrowed form 5c16\n",
        "from keras import datasets\n",
        "from keras.layers import Dense, Flatten, Dropout, Activation\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from keras.models import model_from_json\n",
        "\n",
        "from tensorflow.keras.callbacks import CSVLogger\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "import pickle\n",
        "import sklearn as skl\n",
        "\n",
        "#r2 score\n",
        "#from keras import backend as K\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "#model optimisation api\n",
        "#import tensorflow_model_optimization as tfmot\n",
        "\n",
        "import tempfile\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "%load_ext tensorboard\n",
        "\n",
        "from tabulate import tabulate"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUaWQfvzF40O"
      },
      "source": [
        "# Define some useful functions\r\n",
        "class PlotLossAccuracy(keras.callbacks.Callback):\r\n",
        "    def on_train_begin(self, logs={}):\r\n",
        "        self.i = 0\r\n",
        "        self.x = []\r\n",
        "        self.acc = []\r\n",
        "        self.losses = []\r\n",
        "        self.val_losses = []\r\n",
        "        self.val_acc = []\r\n",
        "        self.logs = []\r\n",
        "        self.metrics = []\r\n",
        "        self.val_metrics = []\r\n",
        "        \r\n",
        "\r\n",
        "    def on_epoch_end(self, epoch, logs={}):\r\n",
        "        \r\n",
        "        self.logs.append(logs)\r\n",
        "        self.x.append(int(self.i))\r\n",
        "        self.losses.append(logs.get('loss'))\r\n",
        "        self.val_losses.append(logs.get('val_loss'))\r\n",
        "        self.acc.append(logs.get('r_squared'))\r\n",
        "        self.val_acc.append(logs.get('val_r_squared'))\r\n",
        "        ###\r\n",
        "        self.metrics.append(logs.get('mean_absolute_percentage_error'))         #mean_squared_error\r\n",
        "        self.val_metrics.append(logs.get('val_mean_absolute_percentage_error')) #val_mean_squared_error\r\n",
        "        \r\n",
        "        \r\n",
        "        self.i += 1\r\n",
        "        \r\n",
        "        clear_output(wait=True)\r\n",
        "        plt.figure(figsize=(60, 20))\r\n",
        "        plt.plot([3, 1])\r\n",
        "\r\n",
        "        #plot 1 mean absolute percentage error\r\n",
        "        plt.subplot(131) \r\n",
        "        plt.plot(self.x, self.losses, label=\"train loss\")\r\n",
        "        plt.plot(self.x, self.val_losses, label=\"validation loss\")\r\n",
        "        plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\r\n",
        "        plt.ylabel('Mse')\r\n",
        "        plt.xlabel('epoch')\r\n",
        "        plt.title('MSE Value')\r\n",
        "        plt.legend()\r\n",
        "\r\n",
        "        #plot 2 r squared value\r\n",
        "        plt.subplot(133)         \r\n",
        "        plt.plot(self.x, self.acc, label=\"training r-squared\")\r\n",
        "        plt.plot(self.x, self.val_acc, label=\"validation r-squared\")\r\n",
        "        plt.legend()\r\n",
        "        plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\r\n",
        "        plt.ylabel('R-squared')\r\n",
        "        plt.xlabel('epoch')\r\n",
        "        plt.title('R-Squared Value')\r\n",
        "\r\n",
        "        #plot 3 mean squared error\r\n",
        "        plt.subplot(132)         \r\n",
        "        plt.plot(self.x, self.metrics, label=\"training mse\")\r\n",
        "        plt.plot(self.x, self.val_metrics, label=\"validation mse\")\r\n",
        "        plt.legend()\r\n",
        "        plt.ylabel('Mean absolute percentage Error')\r\n",
        "        plt.xlabel('epoch')\r\n",
        "        plt.title('Mean absolute percentage Error')\r\n",
        "        \r\n",
        "        plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\r\n",
        "        plt.show();\r\n",
        "        \r\n",
        "\r\n",
        "#creating a r^2 metric for the model evaluation\r\n",
        "def r_squared(y_true, y_pred):\r\n",
        "    SS_res =  K.sum(K.square( y_true-y_pred )) \r\n",
        "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) ) \r\n",
        "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\r\n",
        "\r\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1n0YwZjAbhz"
      },
      "source": [
        "#create a list of channel names \n",
        "ch_names = np.arange(44).tolist()\n",
        "freqs = np.arange(191.6, 195.9, 0.1).tolist()\n",
        "for x in range(len(ch_names)):\n",
        "  ch_names[x] = \"Ch %.0f (%.1f)\" % (ch_names[x], freqs[x])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CY7XJknsPN9f"
      },
      "source": [
        "#generate the train and validation datasets\r\n",
        "#retreiving both datasets from GitHub\r\n",
        "git_xval = 'https://raw.githubusercontent.com/p-owens/MAI/main/x_val.csv'\r\n",
        "git_yval = 'https://raw.githubusercontent.com/p-owens/MAI/main/y_val.csv'\r\n",
        "df_x = pd.read_csv(git_xval,\r\n",
        "                  index_col=False,\r\n",
        "                  header=None,\r\n",
        "                  names=ch_names)\r\n",
        "\r\n",
        "df_y = pd.read_csv(git_yval,\r\n",
        "                  index_col=False,\r\n",
        "                  header=None,\r\n",
        "                  names=ch_names)\r\n",
        "\r\n",
        "#dropping the frequences row for each training sample\r\n",
        "df_x = df_x.iloc[1::2]\r\n",
        "#print(df_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bLhf7cnrlsD"
      },
      "source": [
        "#drop all rows where df_x has a value != 0\n",
        "df_chx = df_x[df_x[ch_names[ch]] !=0].iloc[500:,:]\n",
        "df_chy = df_y[df_y[ch_names[ch]] !=0].iloc[500:,:]\n",
        "df_chy = df_chy[ch_names[ch]]\n",
        "\n",
        "#convert to numpy arrays\n",
        "x_values = df_chx.to_numpy()\n",
        "y_values = df_chy.to_numpy()\n",
        "\n",
        "#adding some samples where the channel is 0\n",
        "#x values\n",
        "df_xzero = df_x.iloc[:500,:]\n",
        "x_values = np.concatenate((x_values, df_xzero.to_numpy()), axis=0)\n",
        "\n",
        "#y values\n",
        "df_yzero = df_y.iloc[:500,ch]\n",
        "y_values = np.concatenate((y_values, df_yzero.to_numpy()), axis=0)\n",
        "\n",
        "\n",
        "#generate the test/validation split\n",
        "val_split = .2\n",
        "x_train, x_val, y_train, y_val = skl.model_selection.train_test_split(x_values, y_values, test_size = val_split, random_state = 0)#renaimed x_rem and y_rem to x_values and y_values\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DntGg6Abc1ee"
      },
      "source": [
        "#loading a previously saved model\n",
        "\"\"\"\n",
        "model_dir = \"ch_14_ep_500_pct_err_5.2_mse_0.0_.h5\"\n",
        "l_rate = 1 * 1e-4\n",
        "\n",
        "model = tf.keras.models.load_model(model_dir, custom_objects={'r_squared': r_squared})\n",
        "model.compile(optimizer=tf.keras.optimizers.Nadam(learning_rate=l_rate),\n",
        "              loss='mean_squared_error',\n",
        "              metrics=[r_squared, tf.keras.metrics.MeanAbsolutePercentageError()])\n",
        "\n",
        "model.summary()\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEXous-TkzsQ"
      },
      "source": [
        "#callback for plotting the model metrics\r\n",
        "#path = \"checkpoint4/\"\r\n",
        "file_name = \"checkpoint/ch_{0}.ckpt\".format(ch)\r\n",
        "log_file = \"model_ch_{0}.csv\".format(ch)\r\n",
        "csv_log = CSVLogger(log_file)\r\n",
        "\r\n",
        "pltCallBack = PlotLossAccuracy()\r\n",
        "#callback for saving the model\r\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath= file_name, #path + file_name + \"ep_{epoch:02d}_mse_{val_loss:.2f}_pct_err_{val_mean_absolute_percentage_error:.2f}.ckpt\", #\r\n",
        "                                                  monitor='val_loss',\r\n",
        "                                                  verbose=1,\r\n",
        "                                                  save_freq=\"epoch\",\r\n",
        "                                                  save_weights_only=False,\r\n",
        "                                                  save_best_only=True,\r\n",
        "                                                  mode='min')\r\n",
        "\r\n",
        "batchSize = 400\r\n",
        "\r\n",
        "# and train\r\n",
        "model.fit(x_train, y_train,\r\n",
        "                    batch_size=batchSize, epochs=750,   #500 ephocs gives ~ 5% error\r\n",
        "                    validation_data=(x_val, y_val), \r\n",
        "                    callbacks=[pltCallBack, checkpoint_callback, csv_log])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95l-lJr3AvU1"
      },
      "source": [
        "#print the logfile of the model training data\n",
        "pd.read_csv(log_file, index_col='epoch')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JUeQ1eGj1ej",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1da54b1a-0fa8-4300-ee1f-928f8b252753"
      },
      "source": [
        "#evaluate the model on the test set\n",
        "results = model.evaluate(x_test,y_test)#, verbose=1)\n",
        "print(\"{name1}\\t\\t: {mse:<.4f}\\t(lower is better)\\n{name2}\\t: {percent_err:<.3%}\\t(lower is better)\".format(name1 = model.metrics_names[0],\n",
        "                                                                                                    name2 = model.metrics_names[2],\n",
        "                                                                                                    mse = results[0],\n",
        "                                                                                                    percent_err = results[2]/100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13/13 [==============================] - 0s 1ms/step - loss: 0.0174 - r_squared: 0.8477 - mean_absolute_percentage_error: 4.5869\n",
            "loss\t\t: 0.0174\t(lower is better)\n",
            "mean_absolute_percentage_error\t: 4.587%\t(lower is better)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}