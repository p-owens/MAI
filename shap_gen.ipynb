{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPu8wFP3B1WW3zHK1LB9dnR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/p-owens/MAI/blob/main/shap_gen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SybsD7J4nblA"
      },
      "source": [
        "pip install shap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pSwPKcsnkdH"
      },
      "source": [
        "#allow file access\n",
        "from google.colab import files\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "import pickle\n",
        "\n",
        "#import shap  \n",
        "import shap\n",
        "shap.initjs()\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_v2_behavior() #this was required for SHAP values\n",
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "#borrowed form 5c16\n",
        "from keras import datasets\n",
        "from keras.layers import Dense, Flatten, Dropout, Activation\n",
        "from keras.regularizers import l2\n",
        "\n",
        "from keras.models import model_from_json\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "import pickle\n",
        "import sklearn as skl\n",
        "\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1n0YwZjAbhz"
      },
      "source": [
        "ch_names = np.arange(44).tolist()\n",
        "freqs = np.arange(191.6, 195.9, 0.1).tolist()\n",
        "for x in range(len(ch_names)):\n",
        "  ch_names[x] = \"Ch %.0f (%.1f)\" % (ch_names[x], freqs[x])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS1WsXmSn2Ag"
      },
      "source": [
        "#retreiving both datasets from GitHub\n",
        "git_xval = 'https://raw.githubusercontent.com/p-owens/MAI/main/x_val.csv'\n",
        "git_yval = 'https://raw.githubusercontent.com/p-owens/MAI/main/y_val.csv'\n",
        "df0 = pd.read_csv(git_xval,\n",
        "                  index_col=False,\n",
        "                  header=None,\n",
        "                  names=ch_names                                   \n",
        "                 )\n",
        "df1 = pd.read_csv(git_yval,\n",
        "                  index_col=False,\n",
        "                  header=None,\n",
        "                  names=ch_names\n",
        "                 )\n",
        "\n",
        "x_values = df0.to_numpy()\n",
        "y_values = df1.to_numpy()\n",
        "\n",
        "#removing the frequency row - treating these values as labels\n",
        "x_values = x_values[1::2,:]\n",
        "\n",
        "#generate the validation and training datasets\n",
        "x_train, x_val, y_train, y_val = skl.model_selection.train_test_split(x_values, y_values, test_size=.2, random_state=0)#renaimed x_rem and y_rem to x_values and y_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hF7HCAijoSVB"
      },
      "source": [
        "#set the channel number here\n",
        "channel = 35"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_m_WtYIoB93"
      },
      "source": [
        "#Using a dataset with 1 ch constantly on for the test set\n",
        "#retreiving both datasets from GitHub\n",
        "\n",
        "\n",
        "\n",
        "git_xval = ('https://raw.githubusercontent.com/p-owens/MAI/main/data%20gen/ch{0}/x_val.csv'.format(channel))\n",
        "git_yval = ('https://raw.githubusercontent.com/p-owens/MAI/main/data%20gen/ch{0}/y_val.csv'.format(channel))\n",
        "dfx = pd.read_csv(git_xval,\n",
        "                  index_col=False,\n",
        "                  header=None,\n",
        "                  names=ch_names                                   \n",
        "                 )\n",
        "dfy = pd.read_csv(git_yval,\n",
        "                  index_col=False,\n",
        "                  header=None,\n",
        "                  names=ch_names\n",
        "                 )\n",
        "x_test = dfx.to_numpy()\n",
        "y_test = dfy.to_numpy()\n",
        "\n",
        "#removing the frequency row - treating these values as labels\n",
        "x_test = x_test[1::2,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYX627VDoVnW"
      },
      "source": [
        "#Load a previously saved model\n",
        "model = tf.keras.models.load_model('model_entire_training_set_l_0.13_me_0.18')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvL2EhA3oak8"
      },
      "source": [
        "#Generate the SHAP values for the model\n",
        "background = x_train[np.random.choice(x_train.shape[0], 4999, replace=False)]\n",
        "explain = shap.DeepExplainer(model, background)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HfBMhGnofLl"
      },
      "source": [
        "#~45 mins to evaluate, ~2300 vals\n",
        "#~15 mins to evaluate, 500 vals\n",
        "shap_values = explain.shap_values(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bwlZf5VoqJc"
      },
      "source": [
        "#saving the shap model evaluated on the test set\n",
        "filename = 'shap_vals_ch{0}.txt'.format(channel)\n",
        "\n",
        "with open(('{0}'.format(filename)), 'wb') as fv:\n",
        "   pickle.dump(shap_values, fv)\n",
        "\n",
        "files.download(('{0}'.format(filename)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXQWk-pAqnGG"
      },
      "source": [
        "#computing the shap values for the effect that all the other channels have on channel 40 (in this case) \n",
        "sv_cpy = shap_values[channel].copy()\n",
        "sv_cpy[:,channel] = 0\n",
        "avg_vec = np.average(np.absolute(sv_cpy), 0)\n",
        "all_avg_s[channel, 1:] = avg_vec\n",
        "\n",
        "#saving the matrix as a .csv\n",
        "df_save = pd.DataFrame(all_avg_s, columns=(['Weights'] + ch_names))\n",
        "df_save.to_csv('all_mean_shap.csv', header=(['Weights'] + ch_names))\n",
        "files.download('all_mean_shap.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdwrCm-Bqq8H"
      },
      "source": [
        "ch = channel\n",
        "print(explain.expected_value[ch])\n",
        "shap.summary_plot(sv_cpy, x_test, sort=True, feature_names=ch_names, plot_type=\"bar\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoZtJvUzqslq"
      },
      "source": [
        "ch = channel\n",
        "print(explain.expected_value[ch])\n",
        "shap.summary_plot(shap_values[ch], x_test, sort=True, feature_names=ch_names , plot_type=\"bar\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}